[global]

#per_job_logs=0
#log_avg_msec=50
#write_bw_log=hhhl_seqread.results
#write_iops_log=hhhl_iops.results
#write_lat_log=hhhl_lat.results


# bs= blocksize for test. Common sizes are 4k, 64k,128k,256k, 512k, 1M

bs=128k

# iodepth = queue depth. Common depths are 32, 64, 126, 256, 512
iodepth=32

# do not change direct value.
direct=1

# do not change ioengine
ioengine=libaio

# do not change randrepeat, this gives validation to test and makes sure you're not just writing on m.2 DRAM buffer stored data.
randrepeat=1

# reports all jobs into the same output. No need to change unless you think there's a single m.2 that's underperforming.
group_reporting

# sets the jobs to run as a time based run. Do not change.
time_based

# runtime is how long the test will run in seconds.
runtime=600

# filesize sets the size of the test file plot.
filesize=10G

# cpus_allowed sets what threads are allowed to be used for testing. Usage : Only use certain cpus by using CSV ie 0,1,2,3 .   Use a range of CPU ie 0-24.
#cpus_allowed=0-23

# cpus_allowed_policy changes how the threads are locked. This can be changed to shared or split. Split dedicates one thread to one job
# shared will allow more than one job to run a thread. Tweak for performance.
cpus_allowed_policy=split

# numjobs sets the amount of threads to run per job. ie. if numbjobs=2 than each job will run two tests on the m.2. Change value to see where performance is the best. 
numjobs=16

# do not change invalidate. If set to 0 your test will not be valid.
invalidate=1

# ramp_time sets the amount of time to warm up the drives. Longer ramp times will fill the write buffer so you are able to log data for sustained writes only.
ramp_time=20

# How to use this job file:
# Job structure is broken down into four values, job number defined as [job$], job type as defined by rw=$$, 
# target for test is defined by filename=/dev/nvme$n$ and the name of the test as defined by name=$$=$$$.



# Remove comment to switch test mode.
# write = seq write
# read = seq read
# rw = seq read and write
# randread random reads
# randwrite = random writes
# randrw = random reads and writes
# trimwrite = before writing the block will be trimmed and then written. Probably won't ever be used.


[job1]
#BUS00 NUMA=0
cpus_allowed=48-63
rw=read
filename=/dev/nvme0n1:/dev/nvme1n1:/dev//dev/nvme2n1:/dev/nvme3n1:/dev/nvme4n1:/dev/nvme5n1:/dev/nvme6n1:/dev/nvme7n1
name=raw=test

[job2]
#BUS20 NUMA=2
cpus_allowed=32-74
rw=read
filename=/dev/nvme8n1:/dev/nvme9n1:/dev/nvme10n1:/dev/nvme11n1:/dev/nvme12n1:/dev/nvme13n1:/dev/nvme14n1:/dev/nvme15n1
name=raw=test

[job3]
#BUS80 NUMA=7 
cpus_allowed=112-127
rw=read
filename=/dev/nvme16n1:/dev/nvme17n1:/dev/nvme18n1:/dev/nvme19n1:/dev/nvme20n1:/dev/nvme21n1:/dev/nvme22n1:/dev/nvme23n1
name=raw=test

[job4]
#BUSc0 NUMA=5
cpus_allowed=80-95
rw=read
filename=/dev/nvme24n1:/dev/nvme25n1:/dev/nvme26n1:/dev/nvme27n1:/dev/nvme28n1:/dev/nvme29n1:/dev/nvme30n1:/dev/nvme31n1
name=raw=test

[job5]
#BUSe0 NUMA=4
cpus_allowed=64-79
rw=read
filename=/dev/nvme32n1:/dev/nvme33n1:/dev/nvme34n1:/dev/nvme35n1:/dev/nvme36n1:/dev/nvme37n1:/dev/nvme38n1:/dev/nvme39n1
name=raw=test

